"""
ãƒ¬ãƒ“ãƒ¥ãƒ¼åˆ†æãƒšãƒ¼ã‚¸
- ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
- AIåŸå­åŒ– + ã‚«ãƒ†ã‚´ãƒªåˆ†é¡
- ã‚«ãƒ†ã‚´ãƒªÃ—ç«¶åˆãƒãƒˆãƒªã‚¯ã‚¹
"""
import streamlit as st
import sys
import json
import ast  # è¿½åŠ : JSONãƒ‘ãƒ¼ã‚¹ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨
import re   # è¿½åŠ : æ­£è¦è¡¨ç¾ç”¨
import pandas as pd
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

from modules.settings_manager import SettingsManager
from modules.data_store import DataStore
from modules.ai_provider import AIProvider
from modules.prompt_manager import PromptManager
from modules.ai_sidebar import render_ai_sidebar

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ãƒ¬ãƒ“ãƒ¥ãƒ¼åˆ†æ - ProductDev",
    page_icon="â­",
    layout="wide"
)

# ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
@st.cache_resource
def get_settings():
    return SettingsManager()

@st.cache_resource
def get_data_store():
    return DataStore()

@st.cache_resource
def get_ai_provider(_settings):
    return AIProvider(_settings)

@st.cache_resource
def get_prompt_manager():
    return PromptManager()

settings = get_settings()
data_store = get_data_store()
ai_provider = get_ai_provider(settings)
prompt_manager = get_prompt_manager()

# ã‚µã‚¤ãƒ‰ãƒãƒ¼
with st.sidebar:
    st.markdown("### ğŸ’¡ ProductDev")
    if st.button("â† ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰"):
        st.switch_page("main.py")
    
    if "current_project" in st.session_state and st.session_state.current_project:
        project = st.session_state.current_project
        st.info(f"ğŸ“ {project.get('name', 'æœªé¸æŠ')}")
    else:
        st.warning("ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’é¸æŠã—ã¦ãã ã•ã„")
        st.switch_page("pages/01_ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ.py")

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç¢ºèª
if "current_project" not in st.session_state or not st.session_state.current_project:
    st.error("ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    st.stop()

project = st.session_state.current_project
project_id = project["id"]

# ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
st.title("â­ ãƒ¬ãƒ“ãƒ¥ãƒ¼åˆ†æ")
st.caption("ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‹ã‚‰ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®å‡ºç¾æ•°ã‚’åˆ†æ")

# ç«¶åˆãƒ‡ãƒ¼ã‚¿å–å¾—
competitors = data_store.list_by_parent("competitors", project_id)
competitor_names = {c["id"]: c["name"] for c in competitors}

# ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
# ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
col1, col2 = st.columns([4, 1])

# æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã‚’ä½¿ç”¨
from modules.file_upload_widget import render_file_uploader, get_dataframes_from_files

with col2:
    # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆèª¿æ•´ã®ãŸã‚ã®ç©ºè¦ç´ 
    pass

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼ï¼ˆå¹…åºƒãå¯¾å¿œï¼‰
processed_files = render_file_uploader(
    key="review_upload",
    label="ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆExcelãƒ»CSVãƒ»PDFãƒ»Wordç­‰ï¼‰",
    allowed_types=["csv", "xlsx", "xls", "txt", "md", "json", "pdf", "docx", "doc"],
    max_files=10,
    show_summary=True,
    show_preview=False
)

if processed_files:
    # ãƒ‡ãƒ¼ã‚¿å‡¦ç†
    all_reviews = []
    has_data = False
    
    try:
        # 1. æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ï¼ˆCSV/Excelï¼‰ã‹ã‚‰ã®æŠ½å‡º
        dataframes = get_dataframes_from_files(processed_files)
        
        if dataframes:
            # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º
            with st.expander("ğŸ“„ ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆExcel/CSVï¼‰", expanded=True):
                # æœ€åˆã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’è¡¨ç¤º
                first_name = list(dataframes.keys())[0]
                st.caption(f"ãƒ•ã‚¡ã‚¤ãƒ«: {first_name}")
                st.dataframe(dataframes[first_name].head(10))
            
            # å„ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’æŠ½å‡º
            for name, df in dataframes.items():
                # ãƒ¬ãƒ“ãƒ¥ãƒ¼åˆ—ã‚’æ¢ç´¢
                review_column = None
                for col in df.columns:
                    col_str = str(col).lower()
                    if "ãƒ¬ãƒ“ãƒ¥ãƒ¼" in col_str or "review" in col_str or "ã‚³ãƒ¡ãƒ³ãƒˆ" in col_str or "æœ¬æ–‡" in col_str or "body" in col_str:
                        review_column = col
                        break
                
                if review_column is None and len(df.columns) > 0:
                    review_column = df.columns[-1]  # è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯æœ€å¾Œã®åˆ—
                
                if review_column:
                    # ãƒ†ã‚­ã‚¹ãƒˆåŒ–ã—ã¦è¿½åŠ 
                    df_reviews = df[review_column].astype(str).tolist()
                    all_reviews.extend([r for r in df_reviews if r and r.lower() != 'nan' and r.lower() != 'none'])
        
        # 2. éæ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ï¼ˆPDF/Word/Textï¼‰ã‹ã‚‰ã®æŠ½å‡º
        for pf in processed_files:
            # CSV/Excelä»¥å¤–ã§ãƒ†ã‚­ã‚¹ãƒˆã‚’æŒã£ã¦ã„ã‚‹ã‚‚ã®
            if pf.get("type") not in ["csv", "excel"] and pf.get("text"):
                # ãƒ†ã‚­ã‚¹ãƒˆã‚’æ®µè½ã‚„è¡Œã§åˆ†å‰²ã—ã¦ãƒªã‚¹ãƒˆåŒ–
                text_content = pf["text"]
                # ç°¡æ˜“çš„ã«æ”¹è¡Œã§åˆ†å‰²ï¼ˆç©ºè¡Œã‚’é™¤ãï¼‰
                lines = [line.strip() for line in text_content.split('\n') if line.strip()]
                if lines:
                    all_reviews.extend(lines)
                    has_data = True

        if all_reviews:
            st.success(f"âœ… åˆè¨ˆ {len(all_reviews)} ä»¶ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼/ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã—ã¾ã—ãŸ")
            has_data = True
        
        if has_data:
            # AIåˆ†æãƒœã‚¿ãƒ³
            if st.button("ğŸ¤– AIã§ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’åˆ†æ", type="primary"):
                with st.spinner("AIåˆ†æä¸­...ï¼ˆä»¶æ•°ãŒå¤šã„å ´åˆã¯æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ï¼‰"):
                    try:
                        # ãƒ†ã‚­ã‚¹ãƒˆçµåˆï¼ˆãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™ã‚’è€ƒæ…®ã—ã¦æœ€å¤§ä»¶æ•°ã‚’åˆ¶é™ï¼‰
                        # 1ä»¶ã‚ãŸã‚Šå¹³å‡100æ–‡å­—ã¨ä»®å®šã—ã¦ã€ç´„200ä»¶ç¨‹åº¦ã«åˆ¶é™
                        target_reviews = all_reviews[:200]
                        reviews_text = "\n".join(target_reviews)
                        
                        if len(all_reviews) > 200:
                            st.warning(f"âš ï¸ ãƒ‡ãƒ¼ã‚¿é‡ãŒå¤šã„ãŸã‚ã€æœ€åˆã®200ä»¶ã®ã¿ã‚’ä½¿ç”¨ã—ã¦åˆ†æã—ã¾ã™ã€‚ï¼ˆå…¨{len(all_reviews)}ä»¶ï¼‰")
                        
                        # åŸå­åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
                        atomize_prompt = prompt_manager.load("atomize")
                        if not atomize_prompt:
                            atomize_prompt = prompt_manager.get_default("atomize")
                        
                        atomize_prompt = atomize_prompt.replace("{{reviews}}", reviews_text)
                        
                        # AIå‘¼ã³å‡ºã—ï¼ˆåŸå­åŒ–ï¼‰
                        atomize_response = ai_provider.generate_with_retry(
                            prompt=atomize_prompt,
                            task="atomize"
                        )
                        
                        # JSONã‚’æŠ½å‡ºï¼ˆå …ç‰¢ç‰ˆï¼‰
                        json_str = atomize_response
                        
                        # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯æŠ½å‡ºã‚’è©¦ã¿ã‚‹
                        match = re.search(r'```(?:json)?\s*(\{[\s\S]*\})\s*```', atomize_response)
                        if match:
                            json_str = match.group(1)
                        else:
                            # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‹ã€æ­£è¦è¡¨ç¾ã§ãƒãƒƒãƒã—ãªã„å ´åˆ
                            # { ã¨ } ã§å›²ã¾ã‚Œã¦ã„ã‚‹æœ€å¤–éƒ­ã®ç¯„å›²ã‚’æŠ½å‡º
                            start = atomize_response.find('{')
                            end = atomize_response.rfind('}')
                            if start != -1 and end != -1 and end > start:
                                json_str = atomize_response[start:end+1]

                        
                        try:
                            keywords_data = json.loads(json_str.strip())
                        except json.JSONDecodeError:
                            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ast.literal_evalã‚’è©¦ã¿ã‚‹ï¼ˆã‚·ãƒ³ã‚°ãƒ«ã‚¯ã‚©ãƒ¼ãƒˆæ–‡å­—å¯¾ç­–ï¼‰
                            try:
                                keywords_data = ast.literal_eval(json_str.strip())
                            except:
                                raise  # ä¸¡æ–¹å¤±æ•—ã—ãŸå ´åˆã¯å…ƒã®ä¾‹å¤–ãªã©
                        
                        keywords = keywords_data.get("keywords", [])
                        
                        # ã‚«ãƒ†ã‚´ãƒªåˆ†é¡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
                        categorize_prompt = prompt_manager.load("categorize")
                        if not categorize_prompt:
                            categorize_prompt = prompt_manager.get_default("categorize")
                        
                        keywords_text = json.dumps(keywords, ensure_ascii=False)
                        categorize_prompt = categorize_prompt.replace("{{keywords}}", keywords_text)
                        
                        # AIå‘¼ã³å‡ºã—ï¼ˆã‚«ãƒ†ã‚´ãƒªåˆ†é¡ï¼‰
                        categorize_response = ai_provider.generate_with_retry(
                            prompt=categorize_prompt,
                            task="categorize"
                        )
                        
                        # JSONã‚’æŠ½å‡ºï¼ˆå …ç‰¢ç‰ˆï¼‰
                        json_str = categorize_response
                        
                        match = re.search(r'```(?:json)?\s*(\{[\s\S]*\})\s*```', categorize_response)
                        if match:
                            json_str = match.group(1)
                        else:
                            start = categorize_response.find('{')
                            end = categorize_response.rfind('}')
                            if start != -1 and end != -1 and end > start:
                                json_str = categorize_response[start:end+1]
                        
                        try:
                            categories_data = json.loads(json_str.strip())
                        except json.JSONDecodeError:
                            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ast.literal_evalã‚’è©¦ã¿ã‚‹
                            try:
                                categories_data = ast.literal_eval(json_str.strip())
                            except:
                                raise

                        
                        # çµæœã‚’ä¿å­˜
                        review_analysis = {
                            "project_id": project_id,
                            "total_reviews": len(all_reviews), # å…¨ä»¶æ•°ã‚’è¨˜éŒ²
                            "analyzed_reviews": len(target_reviews),
                            "categories": categories_data.get("categories", []),
                            "keywords": keywords
                        }
                        
                        # æ—¢å­˜ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼åˆ†æã‚’å‰Šé™¤ã—ã¦æ–°è¦ä½œæˆ
                        existing = data_store.list_by_parent("reviews", project_id)
                        for ex in existing:
                            data_store.delete("reviews", ex["id"])
                        
                        data_store.create("reviews", review_analysis)
                        st.success("âœ… ãƒ¬ãƒ“ãƒ¥ãƒ¼åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸ")
                        st.rerun()
                        
                    except Exception as e:
                        st.error(f"åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
                        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã®è¡¨ç¤º
                        # st.text(str(e))
        else:
            if not dataframes: # DFã‚‚ãªãã€ãƒ†ã‚­ã‚¹ãƒˆã‚‚æŠ½å‡ºã§ããªã‹ã£ãŸå ´åˆ
                st.warning("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")

    except Exception as e:
        st.error(f"å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")

st.markdown("---")

# åˆ†æçµæœè¡¨ç¤º
reviews_data = data_store.list_by_parent("reviews", project_id)

if reviews_data:
    review_analysis = reviews_data[0]
    total_reviews = review_analysis.get("total_reviews", 0)
    categories = review_analysis.get("categories", [])
    keywords = review_analysis.get("keywords", [])
    
    # çµ±è¨ˆæƒ…å ±
    st.markdown(f"**å…¨ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°åˆè¨ˆ: {total_reviews:,}ä»¶**")
    
    # ã‚«ãƒ†ã‚´ãƒªÃ—ç«¶åˆãƒãƒˆãƒªã‚¯ã‚¹
    if categories:
        st.subheader("ğŸ“Š ã‚«ãƒ†ã‚´ãƒªåˆ¥é›†è¨ˆ")
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ‡ãƒ¼ã‚¿ä½œæˆ
        table_data = []
        for cat in categories:
            cat_name = cat.get("name", "")
            cat_keywords = cat.get("keywords", [])
            cat_total = len(cat_keywords) * 10  # ä»®ã®è¨ˆç®—
            cat_percent = round(cat_total / total_reviews * 100, 1) if total_reviews > 0 else 0
            
            table_data.append({
                "ã‚«ãƒ†ã‚´ãƒª": cat_name,
                "åˆè¨ˆ": f"{cat_total} ({cat_percent}%)",
                "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°": len(cat_keywords)
            })
        
        df_categories = pd.DataFrame(table_data)
        
        # ã‚«ãƒ†ã‚´ãƒªã”ã¨ã®å±•é–‹è¡¨ç¤º
        for cat in categories:
            cat_name = cat.get("name", "")
            cat_keywords = cat.get("keywords", [])
            cat_total = len(cat_keywords) * 10
            cat_percent = round(cat_total / total_reviews * 100, 1) if total_reviews > 0 else 0
            
            with st.expander(f"ğŸ“ {cat_name} - {cat_total}ä»¶ ({cat_percent}%)"):
                st.write("**ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰:**")
                keyword_text = ", ".join(cat_keywords[:20])
                st.write(keyword_text)
        
        # ã‚µãƒãƒªãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«
        st.dataframe(df_categories, use_container_width=True, hide_index=True)
    
    # åŸå­åŒ–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ
    if keywords:
        with st.expander("ğŸ“ åŸå­åŒ–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆï¼ˆã‚¯ãƒªãƒƒã‚¯ã§å±•é–‹ï¼‰"):
            for kw in keywords[:50]:
                word = kw.get("word", "")
                sentiment = kw.get("sentiment", "neutral")
                count = kw.get("count", 0)
                
                color = "#22c55e" if sentiment == "positive" else "#ef4444" if sentiment == "negative" else "#64748b"
                st.markdown(f'<span style="color: {color};">â— {word}</span> ({count}ä»¶)', unsafe_allow_html=True)

else:
    st.info("ğŸ“­ ãƒ¬ãƒ“ãƒ¥ãƒ¼åˆ†æãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
    with st.expander("ğŸ’¡ ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿å½¢å¼"):
        sample_df = pd.DataFrame({
            "å•†å“å": ["è£½å“A", "è£½å“A", "è£½å“B"],
            "ãƒ¬ãƒ“ãƒ¥ãƒ¼": ["è»½ãã¦ä½¿ã„ã‚„ã™ã„", "å°‘ã—é‡ã„ã‘ã©æ©Ÿèƒ½ã¯è‰¯ã„", "é™ã‹ã§æ°—ã«å…¥ã£ãŸ"],
            "è©•ä¾¡": [5, 4, 5]
        })
        st.dataframe(sample_df)

# æ¬¡ã¸ãƒœã‚¿ãƒ³
st.markdown("---")
col_back, col_next = st.columns([1, 1])
with col_back:
    if st.button("â† ç«¶åˆåˆ†æã«æˆ»ã‚‹", use_container_width=True):
        st.switch_page("pages/02_ç«¶åˆåˆ†æ.py")
with col_next:
    if st.button("å·®åˆ¥åŒ–æ¤œè¨ã¸é€²ã‚€ â†’", type="primary", use_container_width=True):
        data_store.update("projects", project_id, {"phase": "å·®åˆ¥åŒ–æ¤œè¨", "progress": 60})
        st.switch_page("pages/04_å·®åˆ¥åŒ–æ¤œè¨.py")

# AIã‚µã‚¤ãƒ‰ãƒãƒ¼
if settings.get_api_key(settings.get_provider()):
    context = f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {project.get('name')}\nãƒ¬ãƒ“ãƒ¥ãƒ¼åˆ†æä¸­"
    render_ai_sidebar(ai_provider, context)
